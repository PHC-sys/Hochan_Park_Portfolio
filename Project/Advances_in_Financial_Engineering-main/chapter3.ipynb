{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2020147544/Advances_in_Financial_Engineering/blob/main/chapter3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bSv9K6r0nuXH"
      },
      "source": [
        "# Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D4b0TuNlo-MZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "p = print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "vciALHZJXB6F",
        "outputId": "8011d883-acd4-44d8-84e4-d26fe9239011"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-2eea6eb86acd>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    df0=pd.Series(close.index[df0 – 1], index=close.index[close.shape[0]-df0.shape[0]:])\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '–' (U+2013)\n"
          ]
        }
      ],
      "source": [
        "def getDailyVol(close,span0=100):\n",
        "    '''\n",
        "    daily vol, reindexed to close\n",
        "    - used to set default profit taking and stop-loss limits\n",
        "    '''\n",
        "    df0=close.index.searchsorted(close.index-pd.Timedelta(days=1))\n",
        "    df0=df0[df0>0]\n",
        "    df0=pd.Series(close.index[df0-1], index=close.index[close.shape[0]-df0.shape[0]:])\n",
        "    try: \n",
        "        df0=close.loc[df0.index]/close.loc[df0.values].values-1 # daily returns\n",
        "    except Exception as e:\n",
        "        print(f'error: {e}\\nplease confirm no duplicate indices')\n",
        "    df0=df0.ewm(span=span0).std()\n",
        "    return df0\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DpuYHE00oki-"
      },
      "source": [
        "## Triple-Barrier Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rI-_XkO1Z2gO"
      },
      "outputs": [],
      "source": [
        "def applyPtSlOnT1(close,events,ptSl,molecule):\n",
        "    \n",
        "    '''\n",
        "    Tripple-barrier labeling method\n",
        "    ` Apply stop loss/profit taking, if it takes place before t1 (end of event)\n",
        "\n",
        "    Input: \n",
        "    ` close: pandas series of prices\n",
        "    ` events: pandas df with columns, \n",
        "      — t1: the timestamp of vertical barrier\n",
        "      — trgt: the unit width of the horizontal barriers, expressed in terms of absolute returns\n",
        "    ` ptsl: a list of two non-negative float values\n",
        "      - ptsl[0]: the factor multiplies trgt to set the width of the upper barrier\n",
        "      - ptsl[1]: the factor multiplies trgt to set the width of the lower barrier\n",
        "    ` molecule: a list with the subset of event indices \n",
        "\n",
        "    Output: a Dataframe containing the timestamps at which each barrier was touched, [pt, s1, t1]\n",
        "    ` 0 (inactive barrier) or 1 (active barrier)\n",
        "\n",
        "    '''\n",
        "    events_=events.loc[molecule]    # event df의 일부 가져옴 -> df꼴\n",
        "    out=events_[['t1']].copy(deep=True) # event subset의 t1 값을 가져오기 (vertical barrier timestamp)\n",
        "    if ptSl[0]>0: \n",
        "       pt=ptSl[0]*events_['trgt']\n",
        "    else:\n",
        "       pt=pd.Series(index=events.index) # NaNs\n",
        "\n",
        "    if ptSl[1]>0:\n",
        "       sl=-ptSl[1]*events_['trgt']\n",
        "    else:\n",
        "       sl=pd.Series(index=events.index) # NaNs\n",
        "    \n",
        "    for loc,t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
        "        df0=close[loc:t1] # path prices\n",
        "        df0=(df0/close[loc]-1)*events_.at[loc,'side'] # path returns\n",
        "        out.loc[loc,'sl']=df0[df0<sl[loc]].index.min() # earliest stop loss.\n",
        "        out.loc[loc,'pt']=df0[df0>pt[loc]].index.min() # earliest profit taking.\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linParts(numAtoms,numThreads):\n",
        "    # partition of atoms with a single loop\n",
        "    parts=np.linspace(0,numAtoms,min(numThreads,numAtoms)+1)\n",
        "    parts=np.ceil(parts).astype(int)\n",
        "    return parts\n",
        "\n",
        "def nestedParts(numAtoms,numThreads,upperTriang=False):\n",
        "    # partition of atoms with an inner loop\n",
        "    parts,numThreads_=[0],min(numThreads,numAtoms)\n",
        "    for num in range(numThreads_):\n",
        "        part=1+4*(parts[-1]**2+parts[-1]+numAtoms*(numAtoms+1.)/numThreads_)\n",
        "        part=(-1+part**.5)/2.\n",
        "        parts.append(part)\n",
        "    parts=np.round(parts).astype(int)\n",
        "    if upperTriang: # the first rows are heaviest\n",
        "        parts=np.cumsum(np.diff(parts)[::-1])\n",
        "        parts=np.append(np.array([0]),parts)\n",
        "    return parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def expandCall(kargs):\n",
        "    # Expand the arguments of a callback function, kargs['func']\n",
        "    func=kargs['func']\n",
        "    del kargs['func']\n",
        "    out=func(**kargs)\n",
        "    return out\n",
        "\n",
        "def processJobs_(jobs):\n",
        "    # Run jobs sequentially, for debugging\n",
        "    out=[]\n",
        "    for job in jobs:\n",
        "        out_=expandCall(job)\n",
        "        out.append(out_)\n",
        "    return out\n",
        "\n",
        "import datetime as dt\n",
        "import sys\n",
        "import time\n",
        "\n",
        "def reportProgress(jobNum,numJobs,time0,task):\n",
        "    # Report progress as asynch jobs are completed\n",
        "    msg=[float(jobNum)/numJobs, (time.time()-time0)/60.]\n",
        "    msg.append(msg[1]*(1/msg[0]-1))\n",
        "    timeStamp=str(dt.datetime.fromtimestamp(time.time()))\n",
        "    msg=timeStamp+' '+str(round(msg[0]*100,2))+'% '+task+' done after '+ \\\n",
        "        str(round(msg[1],2))+' minutes. Remaining '+str(round(msg[2],2))+' minutes.'\n",
        "    if jobNum<numJobs:sys.stderr.write(msg+'\\r')\n",
        "    else:sys.stderr.write(msg+'\\n')\n",
        "    return\n",
        "\n",
        "import multiprocessing as mp\n",
        "def processJobs(jobs,task=None,numThreads=24):\n",
        "    # Run in parallel.\n",
        "    # jobs must contain a 'func' callback, for expandCall\n",
        "    if task is None:task=jobs[0]['func'].__name__\n",
        "    pool=mp.Pool(processes=numThreads)\n",
        "    outputs,out,time0=pool.imap_unordered(expandCall,jobs),[],time.time()\n",
        "    # Process asyn output, report progress\n",
        "    for i,out_ in enumerate(outputs,1):\n",
        "        out.append(out_)\n",
        "        reportProgress(i,len(jobs),time0,task)\n",
        "    pool.close();pool.join() # this is needed to prevent memory leaks\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mpPandasObj(func,pdObj,numThreads=24,mpBatches=1,linMols=True,**kargs):\n",
        "    '''\n",
        "    Parallelize jobs, return a dataframe or series\n",
        "    + func: function to be parallelized. Returns a DataFrame\n",
        "    + pdObj[0]: Name of argument used to pass the molecule\n",
        "    + pdObj[1]: List of atoms that will be grouped into molecules\n",
        "    + kwds: any other argument needed by func\n",
        "\n",
        "    Example: df1=mpPandasObj(func,('molecule',df0.index),24,**kwds)\n",
        "    '''\n",
        "    import pandas as pd\n",
        "    if linMols:parts=linParts(len(pdObj[1]),numThreads*mpBatches)\n",
        "    else:parts=nestedParts(len(pdObj[1]),numThreads*mpBatches)\n",
        "\n",
        "    jobs=[]\n",
        "    for i in range(1,len(parts)):\n",
        "        job={pdObj[0]:pdObj[1][parts[i-1]:parts[i]],'func':func}\n",
        "        job.update(kargs)\n",
        "        jobs.append(job)\n",
        "    if numThreads==1:out=processJobs_(jobs)\n",
        "    else: out=processJobs(jobs,numThreads=numThreads)\n",
        "    if isinstance(out[0],pd.DataFrame):df0=pd.DataFrame()\n",
        "    elif isinstance(out[0],pd.Series):df0=pd.Series()\n",
        "    else:return out\n",
        "    for i in out:df0=df0.append(i)\n",
        "    df0=df0.sort_index()\n",
        "    return df0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GkvkBlDvHeMY"
      },
      "outputs": [],
      "source": [
        "def getEvents(close,tEvents,ptSl,trgt,minRet,numThreads,t1=False,side=None):\n",
        "    '''\n",
        "    Getting the time of first touch\n",
        "     \n",
        "    Input:\n",
        "    ` tEvents: the pandas timeindex containing the timestamps that will seed every triple barrier \n",
        "      - the timestamps selected by the sampling procedures \n",
        "    ` minRet: the minimum target return required for running a triple barrier search\n",
        "    ` numThreads: the number of threads concurrently used by the function  \n",
        "\n",
        "    Output: \n",
        "    ` events: a Dataframe\n",
        "      - events.index: event's starttime\n",
        "      - events['t1']: event's endtime\n",
        "      - events['trgt']: event's target\n",
        "      - events['side'] (optional): the algo's position side\n",
        "    '''\n",
        "    # 1) get target\n",
        "    trgt=trgt.loc[tEvents]\n",
        "    trgt=trgt[trgt>minRet] # minRet\n",
        "\n",
        "    # 2) get t1 (max holding period)\n",
        "    if t1 is False:t1=pd.Series(pd.NaT,index=tEvents)\n",
        "    \n",
        "    # 3) form events object, apply stop loss on t1 - triple barrier\n",
        "    if side is None:\n",
        "       side_,ptSl_=pd.Series(1.,index=trgt.index),[ptSl[0],ptSl[0]]\n",
        "    else:\n",
        "       side_,ptSl_=side.loc[trgt.index],ptSl[:2]\n",
        "    \n",
        "    events=pd.concat({'t1':t1,'trgt':trgt,'side':side_}, axis=1).dropna(subset=['trgt'])\n",
        "    df0=mpPandasObj(func=applyPtSlOnT1,pdObj=('molecule',events.index), numThreads=numThreads,close=close,events=events,ptSl=ptSl_)\n",
        "    events['t1']=df0.dropna(how='all').min(axis=1) # pd.min ignores nan\n",
        "    if side is None: # if side value is not existed, remove the column\n",
        "       events=events.drop('side',axis=1)\n",
        "    \n",
        "    return events\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl_oO8el-Nex"
      },
      "source": [
        "## Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JOPurYZaIPw-"
      },
      "outputs": [],
      "source": [
        "def getBins(events,close, t1=None):\n",
        "    '''\n",
        "    Labeling for side and size\n",
        "    Input:\n",
        "    ` events: a Dataframe\n",
        "      - events.index: event's startime\n",
        "      - events['t1']: event's endtime\n",
        "      - events['trgt]: target\n",
        "      - events['side]: algo's position side (optional)\n",
        "    `t1: original vertical barrier\n",
        "         \n",
        "    Output:\n",
        "    ` ret: the return realized at the time of the first touched barrier\n",
        "    ` bin: the label as a function of the sign of the outcome \n",
        "      - Case 1: ('side' not in events): bin in (-1,1) <- label by price action (standard labeling)\n",
        "      - Case 2: ('side' in events): bin in (0,1), i.e. pass or bet <- label by pnl (meta-labeling) \n",
        "    '''\n",
        "    #1) prices aligned with events\n",
        "    events_=events.dropna(subset=['t1'])\n",
        "    px=events_.index.union(events_['t1'].values).drop_duplicates()  \n",
        "    px=close.reindex(px,method='bfill')\n",
        "\n",
        "    #2) create out object\n",
        "    out=pd.DataFrame(index=events_.index)\n",
        "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
        "    if 'side' in events_:\n",
        "        out['ret'] *= events_['side']\n",
        "    out['bin']=np.sign(out['ret'])  # -1, 0, 1 value return\n",
        "\n",
        "    # meta-labeling\n",
        "    if 'side' in events_:\n",
        "        out.loc[out['ret']<=0, 'bin'] = 0\n",
        "    else: \n",
        "        # update binary->0 when vertical barrier is touched\n",
        "        ver_idx = events[events['t1'].isin(t1.values)].index\n",
        "        out.loc[ver_idx, 'bin'] = 0\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "17i6G4T_ITSb"
      },
      "outputs": [],
      "source": [
        "def dropLabels(events,minPtc=.05):\n",
        "    '''\n",
        "    Apply weights, drop labels with insufficient examples\n",
        "\n",
        "    '''\n",
        "    while True:\n",
        "        df0=events['bin'].value_counts(normalize=True)\n",
        "        if df0.min()>minPtc or df0.shape[0]<3: break\n",
        "        print('dropped label',df0.argmin(),df0.min())\n",
        "        events=events[events['bin']!=df0.argmin()]\n",
        "    return events"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNrsn+FDY6VXQVK3QpOW/qj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
